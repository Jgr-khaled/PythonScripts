{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fake News Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Donald Trump just couldn t wish all Americans ...\n",
      "1    House Intelligence Committee Chairman Devin Nu...\n",
      "2    On Friday, it was revealed that former Milwauk...\n",
      "3    On Christmas day, Donald Trump announced that ...\n",
      "4    Pope Francis used his annual Christmas Day mes...\n",
      "Name: text, dtype: object\n",
      "(44898, 6)\n"
     ]
    }
   ],
   "source": [
    "#Load the dataset\n",
    "\n",
    "df = pd.read_csv('fake_news.csv')\n",
    "print(df.head()['text'])\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing the dataset\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Drop any rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Remove any unnecessary columns\n",
    "df = df[['text', 'isFake']]\n",
    "\n",
    "# Clean the text\n",
    "def clean_text(text):\n",
    "    # Remove punctuations and special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = [word for word in text.split() if word not in stop_words]\n",
    "    \n",
    "    text = ' '.join(text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "\n",
    "#print(df['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['isFake'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a TF-IDF vectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "#print(tfidf_vectorizer.get_feature_names())\n",
    "#print(tfidf_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9924899650394924\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "\n",
    "# Create a PassiveAggressiveClassifier\n",
    "pac = PassiveAggressiveClassifier(max_iter=50)\n",
    "\n",
    "# Fit the model\n",
    "pac.fit(tfidf_train, y_train)\n",
    "\n",
    "# Predict on the test set and calculate accuracy\n",
    "y_pred = pac.predict(tfidf_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4198   23]\n",
      " [  35 3467]]\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(cm)        #  [ [TP, FP],\n",
    "                 #    [FN, TN]  ]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b348fca72b2f7b5d298eae5c943a38b2c1fc0905995910a8a935ddb3ba2538e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
